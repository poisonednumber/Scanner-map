# Production Docker Compose - Uses pre-built images from Docker Hub
# This file uses published images instead of building locally
# Use this when scanner-map is published to Docker Hub
#
# Usage: docker-compose -f docker-compose.prod.yml up -d

version: '3.8'

services:
  scanner-map:
    # TODO: Replace with actual Docker Hub image when published
    # Example: image: poisonednumber/scanner-map:latest
    # For now, this will fail until the image is published
    image: poisonednumber/scanner-map:latest
    container_name: scanner-map
    restart: unless-stopped
    ports:
      - "${WEBSERVER_PORT:-3001}:3001"  # Web interface
      - "${BOT_PORT:-3306}:3306"         # API endpoint for TrunkRecorder/SDRTrunk
    volumes:
      - ./appdata/scanner-map/data:/app/data                 # Database and API keys
      - ./appdata/scanner-map/audio:/app/audio               # Audio file storage
      - ./appdata/scanner-map/logs:/app/logs                 # Log files
      - ./.env:/app/.env                 # Configuration
      - ./talkgroups.csv:/app/talkgroups.csv:ro  # Talk groups (read-only)
      # Mount other service configs for auto-configuration
      - ./appdata/trunk-recorder/config:/app/appdata/trunk-recorder/config  # For API key auto-config
      - ./appdata/icad-transcribe:/app/appdata/icad-transcribe  # For API key auto-config
    environment:
      - NODE_ENV=production
    networks:
      - scanner-network
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3001/api/test', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Ollama (OPTIONAL) - Local AI Service
  # Uncomment below to enable Ollama for AI features
  # Official: https://ollama.com
  # NOTE: Always pulls from Docker Hub (never builds locally)
  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: ollama
  #   restart: unless-stopped
  #   volumes:
  #     - ./appdata/ollama:/root/.ollama  # Persistent model storage
  #   ports:
  #     - "11434:11434"  # Ollama API port
  #   networks:
  #     - scanner-network
  #   # For GPU support, uncomment the deploy section:
  #   # deploy:
  #   #   resources:
  #   #     reservations:
  #   #       devices:
  #   #         - driver: nvidia
  #   #           count: all
  #   #           capabilities: [gpu]
  #   # After starting, pull a model: docker exec -it ollama ollama pull llama3.1:8b
  #   # Configure OLLAMA_URL=http://ollama:11434 in Scanner Map .env

  # TrunkRecorder (OPTIONAL) - GPL-3.0 Licensed
  # Uncomment below to enable TrunkRecorder integration
  # See LICENSE_NOTICE.md for license information
  # NOTE: Always pulls from Docker Hub (never builds locally)
  # trunk-recorder:
  #   image: lwcooper/trunk-recorder:latest
  #   container_name: trunk-recorder
  #   restart: unless-stopped
  #   privileged: true
  #   devices:
  #     - /dev/bus/usb:/dev/bus/usb  # USB devices for SDR
  #   volumes:
  #     - ./appdata/trunk-recorder/config:/config
  #     - ./appdata/trunk-recorder/recordings:/recordings
  #   environment:
  #     - TZ=${TIMEZONE:-UTC}
  #   networks:
  #     - scanner-network
  #   # TrunkRecorder will upload to scanner-map:3306/api/call-upload
  #   # Configure this in trunk-recorder/config/config.json
  #   # License: GPL-3.0
  #   # Official Repository: https://github.com/TrunkRecorder/trunk-recorder
  #   # Docker Repository: https://github.com/TrunkRecorder/trunk-recorder-docker

networks:
  scanner-network:
    driver: bridge

# All data is stored in ./appdata/ directory for easy management
# To remove all data: rm -rf ./appdata

